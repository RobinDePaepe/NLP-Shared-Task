{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1364,
     "status": "ok",
     "timestamp": 1619947923622,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "SIwQxqum11Li",
    "outputId": "75a74d02-e7cb-4c75-81b9-a12948a84674"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn version: 0.23.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "print('sklearn version: {}'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17020,
     "status": "ok",
     "timestamp": 1619948012698,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "vYhNjt3S2BN7",
    "outputId": "34e58598-4be8-45bb-ea68-cabf731163b0"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "TeZ77nwI2DFR"
   },
   "outputs": [],
   "source": [
    "#for colab\n",
    "#train_path = '/content/drive/My Drive/NLP2021/NLI-proficiency-shared-task/train.csv'\n",
    "#test_path = '/content/drive/My Drive/NLP2021/NLI-proficiency-shared-task/test.csv'\n",
    "\n",
    "#loading corpus\n",
    "train_path = 'Data/train.csv'\n",
    "test_path = 'Data/test.csv'\n",
    "\n",
    "train = pd.read_csv(train_path, sep=',')\n",
    "test = pd.read_csv(test_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "VaAfx-v0_vOe"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#splitting \n",
    "x_train, x_dev, y_train, y_dev = train_test_split(train['text'], train['Language'], test_size = 0.1, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1619854739479,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "nzgdaJHECdD2",
    "outputId": "dfe32286-9397-4199-fdd8-ddfe55118ed3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2801</th>\n",
       "      <td>I agree with the following statement that the ...</td>\n",
       "      <td>ZHO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9674</th>\n",
       "      <td>Life has  various stages, each stage has there...</td>\n",
       "      <td>HIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10836</th>\n",
       "      <td>Nowadays life is tough and expensive and young...</td>\n",
       "      <td>ARA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7349</th>\n",
       "      <td>Well,  I have several reasons to believe that ...</td>\n",
       "      <td>SPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>It is natural that a student studying harder c...</td>\n",
       "      <td>KOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4023</th>\n",
       "      <td>If we happen to consider this issue from an ac...</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>\\tI certainly thinks that having a broad range...</td>\n",
       "      <td>KOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>I disagree that the many academic subjects to ...</td>\n",
       "      <td>SPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3775</th>\n",
       "      <td>I think that understanding a concept about a s...</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10137</th>\n",
       "      <td>Yes, this right. Most advertisements make prod...</td>\n",
       "      <td>ZHO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9900 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Language\n",
       "2801   I agree with the following statement that the ...      ZHO\n",
       "9674   Life has  various stages, each stage has there...      HIN\n",
       "10836  Nowadays life is tough and expensive and young...      ARA\n",
       "7349   Well,  I have several reasons to believe that ...      SPA\n",
       "7581   It is natural that a student studying harder c...      KOR\n",
       "...                                                  ...      ...\n",
       "4023   If we happen to consider this issue from an ac...      TUR\n",
       "7259   \\tI certainly thinks that having a broad range...      KOR\n",
       "5200   I disagree that the many academic subjects to ...      SPA\n",
       "3775   I think that understanding a concept about a s...      ITA\n",
       "10137  Yes, this right. Most advertisements make prod...      ZHO\n",
       "\n",
       "[9900 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = {'Text': x_train,'Language': y_train}\n",
    "df_train = pd.DataFrame(df_train)\n",
    "#df_train = df_train.set_index('Text')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "executionInfo": {
     "elapsed": 351,
     "status": "ok",
     "timestamp": 1619854740271,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "8424s2TCDB0M",
    "outputId": "380335cf-b8b1-4f0e-be0f-023227ebf853"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4293</th>\n",
       "      <td>\\tSpecializing in one specific subject is bett...</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>I agree with the statement. In my opinion it i...</td>\n",
       "      <td>DEU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5630</th>\n",
       "      <td>as far as i concerned i agree with the stateme...</td>\n",
       "      <td>TEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6880</th>\n",
       "      <td>\\tNowadays,  people argue that young people en...</td>\n",
       "      <td>TUR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5347</th>\n",
       "      <td>I will agree with the given statement which is...</td>\n",
       "      <td>TEL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>in this case i could agree because when someon...</td>\n",
       "      <td>SPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1702</th>\n",
       "      <td>Nowadays, we can see a lot of cars in all stre...</td>\n",
       "      <td>FRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6723</th>\n",
       "      <td>Everyday in our lives we can see products' adv...</td>\n",
       "      <td>ITA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>To me, the whole point of advertising is to se...</td>\n",
       "      <td>SPA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>There has been a on going debate whether it is...</td>\n",
       "      <td>KOR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text Language\n",
       "4293  \\tSpecializing in one specific subject is bett...      TUR\n",
       "5742  I agree with the statement. In my opinion it i...      DEU\n",
       "5630  as far as i concerned i agree with the stateme...      TEL\n",
       "6880  \\tNowadays,  people argue that young people en...      TUR\n",
       "5347  I will agree with the given statement which is...      TEL\n",
       "...                                                 ...      ...\n",
       "1059  in this case i could agree because when someon...      SPA\n",
       "1702  Nowadays, we can see a lot of cars in all stre...      FRA\n",
       "6723  Everyday in our lives we can see products' adv...      ITA\n",
       "677   To me, the whole point of advertising is to se...      SPA\n",
       "406   There has been a on going debate whether it is...      KOR\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {'text': x_dev,'Language': y_dev}\n",
    "df_dev = pd.DataFrame(d)\n",
    "#df_dev = df_dev.set_index('Text')\n",
    "df_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnewHxHZm9HM"
   },
   "source": [
    "## Dummy models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "bk2t1-4snb6r"
   },
   "outputs": [],
   "source": [
    "# loading data\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1619367215701,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "ZacPh5mwoRum",
    "outputId": "f968850b-c9e6-4e24-e14f-f276898b5d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform baseline: 0.08681818181818182\n",
      "Most frequent baseline: 0.09090909090909091\n",
      "Stratified baseline: 0.08636363636363636\n"
     ]
    }
   ],
   "source": [
    "#baseline testing\n",
    "\n",
    "X_dummy = train['text']\n",
    "y_dummy= train['Language']\n",
    "\n",
    "dummy_clf_1 = DummyClassifier(strategy=\"uniform\", random_state=1)\n",
    "dummy_clf_1.fit(X_dummy,y_dummy)\n",
    "print(\"Uniform baseline: {}\".format(dummy_clf_1.score(X_dummy,y_dummy)))\n",
    "\n",
    "dummy_clf_2 = DummyClassifier(strategy=\"most_frequent\", random_state=1)\n",
    "dummy_clf_2.fit(X_dummy,y_dummy)\n",
    "print(\"Most frequent baseline: {}\".format(dummy_clf_2.score(X_dummy,y_dummy)))\n",
    "\n",
    "dummy_clf_3 = DummyClassifier(strategy=\"stratified\", random_state=1)\n",
    "dummy_clf_3.fit(X_dummy,y_dummy)\n",
    "print(\"Stratified baseline: {}\".format(dummy_clf_3.score(X_dummy,y_dummy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dmodel = train['text']\n",
    "y_dmodel = train['Language']\n",
    "# split data in train en test set\n",
    "X_dmodel_train, X_dmodel_test, y_dmodel_train, y_dmodel_test = train_test_split(X_dmodel, y_dmodel, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vectorizer and classifiers\n",
    "tfvect = CountVectorizer()\n",
    "tfidfvect = TfidfVectorizer()\n",
    "svm = SVC()\n",
    "linsvm = LinearSVC()\n",
    "tree = DecisionTreeClassifier()\n",
    "neighbors = KNeighborsClassifier()\n",
    "gaussian = GaussianNB()\n",
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', SVC())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", svm)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.51      0.49      0.50        98\n",
      "         DEU       0.64      0.65      0.64       113\n",
      "         FRA       0.56      0.65      0.60        95\n",
      "         HIN       0.54      0.59      0.57       101\n",
      "         ITA       0.59      0.56      0.58       105\n",
      "         JPN       0.53      0.59      0.56        96\n",
      "         KOR       0.63      0.50      0.56       103\n",
      "         SPA       0.49      0.45      0.47       106\n",
      "         TEL       0.63      0.68      0.66        92\n",
      "         TUR       0.56      0.49      0.52        97\n",
      "         ZHO       0.60      0.62      0.61        94\n",
      "\n",
      "    accuracy                           0.57      1100\n",
      "   macro avg       0.57      0.57      0.57      1100\n",
      "weighted avg       0.57      0.57      0.57      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', SVC())])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", svm)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.51      0.49      0.50        98\n",
      "         DEU       0.64      0.65      0.64       113\n",
      "         FRA       0.56      0.65      0.60        95\n",
      "         HIN       0.54      0.59      0.57       101\n",
      "         ITA       0.59      0.56      0.58       105\n",
      "         JPN       0.53      0.59      0.56        96\n",
      "         KOR       0.63      0.50      0.56       103\n",
      "         SPA       0.49      0.45      0.47       106\n",
      "         TEL       0.63      0.68      0.66        92\n",
      "         TUR       0.56      0.49      0.52        97\n",
      "         ZHO       0.60      0.62      0.61        94\n",
      "\n",
      "    accuracy                           0.57      1100\n",
      "   macro avg       0.57      0.57      0.57      1100\n",
      "weighted avg       0.57      0.57      0.57      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", neighbors)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.14      0.28      0.19        98\n",
      "         DEU       0.34      0.35      0.35       113\n",
      "         FRA       0.24      0.41      0.30        95\n",
      "         HIN       0.32      0.19      0.24       101\n",
      "         ITA       0.23      0.41      0.29       105\n",
      "         JPN       0.29      0.30      0.29        96\n",
      "         KOR       0.36      0.20      0.26       103\n",
      "         SPA       0.24      0.21      0.22       106\n",
      "         TEL       0.47      0.26      0.34        92\n",
      "         TUR       0.22      0.08      0.12        97\n",
      "         ZHO       0.28      0.13      0.18        94\n",
      "\n",
      "    accuracy                           0.26      1100\n",
      "   macro avg       0.28      0.26      0.25      1100\n",
      "weighted avg       0.28      0.26      0.25      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeciscionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", tree)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ARA       0.22      0.24      0.23        98\n",
      "         DEU       0.23      0.27      0.25       113\n",
      "         FRA       0.27      0.28      0.28        95\n",
      "         HIN       0.24      0.23      0.24       101\n",
      "         ITA       0.27      0.26      0.26       105\n",
      "         JPN       0.29      0.29      0.29        96\n",
      "         KOR       0.28      0.27      0.28       103\n",
      "         SPA       0.17      0.16      0.16       106\n",
      "         TEL       0.33      0.32      0.32        92\n",
      "         TUR       0.16      0.16      0.16        97\n",
      "         ZHO       0.16      0.14      0.15        94\n",
      "\n",
      "    accuracy                           0.24      1100\n",
      "   macro avg       0.24      0.24      0.24      1100\n",
      "weighted avg       0.24      0.24      0.24      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 578,
     "status": "ok",
     "timestamp": 1619367215701,
     "user": {
      "displayName": "BoundingSlinky",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg39-hR_TNqJ_59YNcAIkf6SEDK7ZIZhvMbODZQUg=s64",
      "userId": "06113191287291968679"
     },
     "user_tz": -120
    },
    "id": "ZacPh5mwoRum",
    "outputId": "f968850b-c9e6-4e24-e14f-f276898b5d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform baseline: 0.3407272727272727\n",
      "Most frequent baseline: 0.5421818181818182\n",
      "Stratified baseline: 0.4289090909090909\n"
     ]
    }
   ],
   "source": [
    "#baseline testing\n",
    "\n",
    "X_dummy = train['text']\n",
    "y_dummy= train['Proficiency']\n",
    "\n",
    "dummy_clf_1 = DummyClassifier(strategy=\"uniform\", random_state=1)\n",
    "dummy_clf_1.fit(X_dummy,y_dummy)\n",
    "print(\"Uniform baseline: {}\".format(dummy_clf_1.score(X_dummy,y_dummy)))\n",
    "\n",
    "dummy_clf_2 = DummyClassifier(strategy=\"most_frequent\", random_state=1)\n",
    "dummy_clf_2.fit(X_dummy,y_dummy)\n",
    "print(\"Most frequent baseline: {}\".format(dummy_clf_2.score(X_dummy,y_dummy)))\n",
    "\n",
    "dummy_clf_3 = DummyClassifier(strategy=\"stratified\", random_state=1)\n",
    "dummy_clf_3.fit(X_dummy,y_dummy)\n",
    "print(\"Stratified baseline: {}\".format(dummy_clf_3.score(X_dummy,y_dummy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dmodel = train['text']\n",
    "y_dmodel = train['Proficiency']\n",
    "# split data in train en test set\n",
    "X_dmodel_train, X_dmodel_test, y_dmodel_train, y_dmodel_test = train_test_split(X_dmodel, y_dmodel, test_size=0.10, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', SVC())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", svm)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.74      0.62      0.67       393\n",
      "         low       0.85      0.52      0.64       120\n",
      "      medium       0.70      0.84      0.76       587\n",
      "\n",
      "    accuracy                           0.72      1100\n",
      "   macro avg       0.76      0.66      0.69      1100\n",
      "weighted avg       0.73      0.72      0.72      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', SVC())])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", svm)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.74      0.62      0.67       393\n",
      "         low       0.85      0.52      0.64       120\n",
      "      medium       0.70      0.84      0.76       587\n",
      "\n",
      "    accuracy                           0.72      1100\n",
      "   macro avg       0.76      0.66      0.69      1100\n",
      "weighted avg       0.73      0.72      0.72      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', KNeighborsClassifier())])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", neighbors)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.65      0.37      0.47       393\n",
      "         low       0.42      0.74      0.54       120\n",
      "      medium       0.62      0.70      0.65       587\n",
      "\n",
      "    accuracy                           0.58      1100\n",
      "   macro avg       0.56      0.60      0.55      1100\n",
      "weighted avg       0.61      0.58      0.58      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeciscionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vec', CountVectorizer()), ('cls', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pipeline\n",
    "pipe = Pipeline([(\"vec\", tfvect), (\"cls\", tree)])\n",
    "pipe.fit(X_dmodel_train, y_dmodel_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        high       0.54      0.49      0.51       393\n",
      "         low       0.47      0.49      0.48       120\n",
      "      medium       0.60      0.63      0.62       587\n",
      "\n",
      "    accuracy                           0.57      1100\n",
      "   macro avg       0.54      0.54      0.54      1100\n",
      "weighted avg       0.56      0.57      0.56      1100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "y_test_pred = pipe.predict(X_dmodel_test)\n",
    "\n",
    "# accuracy\n",
    "print(classification_report(y_dmodel_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM and Linear SVM seem like the best options so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
